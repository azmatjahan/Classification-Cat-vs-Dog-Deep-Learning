{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os , shutil\n",
    "import sys\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" After extracting cats and dogs dataset we have two sub folders (test1 and train) inside the main folder \n",
    "(which i named as \"catdog\") . So, i have assigned two variables for each sub folder .\n",
    "Because of this step we wont get any kinda file path error at the time of copying selected images in new folder \"\"\"\n",
    "\n",
    "original_train_dataset_dir = 'C:Users/HP/.keras/datasets/cat_dog/train'   #adding sub (train) at the end \n",
    "original_test_dataset_dir = 'C:Users/HP/.keras/datasets/cat_dog/test1'    #adding sub (test1) at the end\n",
    " \n",
    "#creating new folder as cats_dogs_selected\n",
    "\n",
    "base_dir = 'C:Users/HP/.keras/datasets/cats_dogs_selected'  \n",
    "#os.mkdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating 3 sub folders \n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "#os.mkdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "#os.mkdir(validation_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.path.join(base_dir, 'test')\n",
    "#os.mkdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:Users/HP/.keras/datasets/cats_dogs_selected\\\\validation'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a folder \"cats\" inside the \"train\" folder \n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "#os.mkdir(train_cats_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a folder \"dogs\" inside the \"train\" folder\n",
    "\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "#os.mkdir(train_dogs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a folder \"cats\" inside the \"validation\" folder \n",
    "\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "#os.mkdir(validation_cats_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a folder \"dogs\" inside the \"validation\" folder\n",
    "\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "#os.mkdir(validation_dogs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a folder \"cats\" inside the \"test\" folder\n",
    "\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "#os.mkdir(test_cats_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a folder \"dogs\" inside the \"test\" folder\n",
    "\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "#os.mkdir(test_dogs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#copying first 1000 images of cats for training in \"cats_dogs_selected --> train --> cats\" folder \n",
    "\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_train_dataset_dir, fname)\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    #shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying 500 images for validation after the series of 1000 images of cats in \"cats_dogs_selected --> validation --> cats\" folder\n",
    "\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_train_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    #shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying 500 images for testing after the series of 1500 images of cats in \"cats_dogs_selected --> test--> cats\" folder\n",
    "\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_train_dataset_dir, fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    #shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying first 1000 images of dogs for training in \"cats_dogs_selected --> train --> dogs\" folder \n",
    "\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_train_dataset_dir, fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    #shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying 500 images for validation after the series of 1000 images of dogs in \"cats_dogs_selected --> validation --> dogs\" folder\n",
    "\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_train_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    #shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying 500 images for testing after the series of 1500 images of dogs in \"cats_dogs_selected --> test--> dogs\" folder\n",
    "\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_train_dataset_dir, fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    #shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training cat images: 1000\n",
      "total training dog images: 1000\n"
     ]
    }
   ],
   "source": [
    "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
    "\n",
    "print('total training dog images:', len(os.listdir(train_dogs_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total validation cat images: 500\n",
      "total validation dog images: 500\n"
     ]
    }
   ],
   "source": [
    "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
    "\n",
    "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total test cat images: 500\n",
      "total test dog images: 500\n"
     ]
    }
   ],
   "source": [
    "print('total test cat images:', len(os.listdir(test_cats_dir)))\n",
    "\n",
    "print('total test dog images:', len(os.listdir(test_dogs_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,target_size=(150, 150),batch_size=20,class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir, target_size=(150, 150), batch_size=20, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape: (20, 150, 150, 3)\n",
      "labels batch shape: (20,)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 171s 2s/step - loss: 0.6849 - acc: 0.5435 - val_loss: 0.6788 - val_acc: 0.5120\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 169s 2s/step - loss: 0.6517 - acc: 0.6160 - val_loss: 0.6500 - val_acc: 0.5830\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 165s 2s/step - loss: 0.5965 - acc: 0.6865 - val_loss: 0.6039 - val_acc: 0.6540\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 171s 2s/step - loss: 0.5586 - acc: 0.7100 - val_loss: 0.5864 - val_acc: 0.6810\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 171s 2s/step - loss: 0.5245 - acc: 0.7310 - val_loss: 0.6100 - val_acc: 0.6740\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 180s 2s/step - loss: 0.5032 - acc: 0.7605 - val_loss: 0.5574 - val_acc: 0.6940\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 169s 2s/step - loss: 0.4737 - acc: 0.7850 - val_loss: 0.5578 - val_acc: 0.7080\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 168s 2s/step - loss: 0.4534 - acc: 0.7860 - val_loss: 0.5415 - val_acc: 0.7160\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 172s 2s/step - loss: 0.4185 - acc: 0.8090 - val_loss: 0.5469 - val_acc: 0.7250\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 174s 2s/step - loss: 0.4060 - acc: 0.8210 - val_loss: 0.5463 - val_acc: 0.7260\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 165s 2s/step - loss: 0.3714 - acc: 0.8375 - val_loss: 0.5492 - val_acc: 0.7170\n",
      "Epoch 12/30\n",
      " 41/100 [===========>..................] - ETA: 1:24 - loss: 0.3744 - acc: 0.8329"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,steps_per_epoch=100,epochs=30,validation_data=validation_generator,\n",
    "                              validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cats_and_dogs_small_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
